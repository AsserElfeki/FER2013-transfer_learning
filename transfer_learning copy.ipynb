{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.mps \n",
    "import itertools\n",
    "import csv\n",
    "from torchmetrics import Accuracy\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import cv2\n",
    "from torchmetrics import Accuracy\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS found\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    print(\"MPS found\")\n",
    "    device = torch.device(\"mps\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_path = './data/FER2013Train'\n",
    "test_folder_path = './data/FER2013Test'\n",
    "valid_folder_path = './data/FER2013Valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERPlusDataset(Dataset):\n",
    "    \"\"\"FERPlus dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.img_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get the unique classes from the emotions column\n",
    "        self.classes = self.img_frame.iloc[:, 2:].shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_frame)\n",
    "\n",
    "#     to access elements using the []\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "#   to create the image name\n",
    "        img_name = os.path.join(self.root_dir, self.img_frame.iloc[idx, 0])\n",
    "\n",
    "        gray_image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
    "        # color_image = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # image = io.imread(img_name)\n",
    "        image = Image.fromarray(gray_image)\n",
    "        emotions = self.img_frame.iloc[idx, 2:]\n",
    "        emotions = np.asarray(emotions)\n",
    "        emotions = emotions.astype('float32')\n",
    "\n",
    "        sample = {'image': image, 'emotions': emotions} # a dictionary of an image with its label\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "        return sample #return a transformed image with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aug(aug):\n",
    "    torch.manual_seed(17) #https://pytorch.org/vision/stable/transforms.html\n",
    "    \n",
    "    if aug:\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomApply([transforms.RandomAffine(0, translate=(0.2, 0.2))], p=0.5),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomApply([transforms.RandomRotation(10)], p=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "            ]),\n",
    "            'valid': transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "            ]),\n",
    "        }\n",
    "        \n",
    "    else: \n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "            ]),\n",
    "            'valid': transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "            ]),\n",
    "        }\n",
    "    return data_transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_path = 'stats/RESNET-Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_table (epochs, optimizer ,criterion, batch_size, learning_rate, elapsed_time,train_loss, train_accuracy, valid_loss, valid_accuracy, trial_id, scheduler, device_name, aug, weight_freezing, f1, precision_score, recall_score): \n",
    "    with open(f'{outputs_path}/statistics.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        if csvfile.tell() == 0:\n",
    "            # Write the column headers\n",
    "            writer.writerow(['trial', 'Batch size', 'Epochs', 'Loss function', 'Initial Learning rate', 'Optimizer', 'Scheduler', \n",
    "                             'Data augmentation', 'Weight freezing', 'f1_score', 'recall_score', 'precision_score',\n",
    "                             'Min training loss', 'Average training loss', 'Max training loss', \n",
    "                             'Min training accuracy %', 'Average training accuracy %', 'Max training accuracy %',\n",
    "                             'Min validation loss', 'Average validation loss', 'Max validation loss', \n",
    "                             'Min validation accuracy %', 'Average validation accuracy %',  'Max validation accuracy %', \n",
    "                             'Total time','Device'])\n",
    "\n",
    "        # Write the row of data\n",
    "        writer.writerow([trial_id, batch_size, epochs, criterion, learning_rate, optimizer, scheduler,\n",
    "                         aug, weight_freezing, round(f1, 2), round(recall_score, 2), round (precision_score, 2), \n",
    "                         round(min(train_loss), 2), round(sum(train_loss) / len(train_loss), 2), round(max(train_loss), 2),\n",
    "                         round(min(train_accuracy), 2), round(sum(train_accuracy) / len(train_accuracy), 2), round(max(train_accuracy), 2),\n",
    "                         round(min(valid_loss), 2), round(sum(valid_loss) / len(valid_loss), 2), round(max(valid_loss), 2),\n",
    "                         round(min(valid_accuracy), 2), round(sum(valid_accuracy) / len(valid_accuracy), 2), round(max(valid_accuracy), 2),\n",
    "                         time.strftime('%H:%M:%S', time.gmtime(elapsed_time)), device_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(epochs, train_accuracy, valid_accuracy, train_loss, valid_loss):      \n",
    "    # Plotting the loss and accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs+1), train_loss, label='Training')\n",
    "    plt.plot(range(1, epochs+1), valid_loss, label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs+1), train_accuracy, label='Training')\n",
    "    plt.plot(range(1, epochs+1), valid_accuracy, label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_details_to_text (epochs, optimizer, scheduler ,criterion, batch_size, learning_rate, id):    \n",
    "    # Create a file to write the output\n",
    "    filename = f'{outputs_path}/trial_details/trial_{id+24}'\n",
    "    output_file = open(filename, \"w\")\n",
    "\n",
    "    output_file.write(f\"Parameter Combination: \\n\")\n",
    "    output_file.write(f\"epochs: {epochs} \\n\")\n",
    "    output_file.write(f\"initial learning_rate: {learning_rate} \\n\")\n",
    "    output_file.write(f\"batch_size: {batch_size} \\n\")\n",
    "    output_file.write(f\"optimizer: {optimizer} \\n\")\n",
    "    output_file.write(f\"scheduler: {scheduler} \\n\")\n",
    "    output_file.write(f\"criterion: {criterion} \\n\")\n",
    "    output_file.write(f\"\\n\")\n",
    "    \n",
    "    output_file.write(f\"Finished Training with this combination\\n\")\n",
    "    \n",
    "    output_file.write(\"#\"*70)\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchmetrics_accuracy = Accuracy(task='multiclass', num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'Neutral',\n",
    "    'Happinnes',\n",
    "    'Surprise',\n",
    "    'Sadness',\n",
    "    'Anger',\n",
    "    'Disgust',\n",
    "    'Fear',\n",
    "    'Contempt',\n",
    "    'Unknown', \n",
    "    'NF'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(epochs, optimizer, scheduler ,criterion, model, trainloader, validloader, batch_size, learning_rate, trial_id, device, aug, weight_freezing):\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    valid_loss = []\n",
    "    valid_accuracy = []\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    opt_name = optimizer.__name__\n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    scheduler = scheduler(optimizer, gamma=0.9)\n",
    "        \n",
    "    st = time.time()\n",
    "\n",
    "# Training - Validation loop\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        # Perform training\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            labels = data['emotions'].to(device)\n",
    "            inputs = data['image'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() \n",
    "\n",
    "            # Calculate and store training accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            \n",
    "            # total += labels.size(0) \n",
    "            # correct +=  (predicted == labels).sum().item()\n",
    "            # print(\"1 more correct..\")\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Calculate and store training loss\n",
    "        train_loss.append(running_loss / len(trainloader))\n",
    "        train_accuracy.append(100 * torchmetrics_accuracy(predicted, labels).item())\n",
    "\n",
    "        # Perform validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for data in validloader:\n",
    "                labels = data['emotions'].to(device)\n",
    "                images = data['image'].to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                \n",
    "                # total += labels.size(0)\n",
    "                # correct +=  (predicted == labels).sum().item() #can be torch.eq(pred, labels).sum().item()\n",
    "\n",
    "                 # Store predicted and true labels for calculating metrics\n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "        valid_loss.append(running_loss / len(validloader))\n",
    "        valid_accuracy.append(100 * torchmetrics_accuracy(predicted, labels).item())\n",
    "      \n",
    "\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    cm_display = ConfusionMatrixDisplay.from_predictions(y_true=true_labels, y_pred=predicted_labels, normalize='true', display_labels=classes)\n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    cm_display.plot(ax=ax, cmap='Blues', values_format='0.2f', xticks_rotation=45)\n",
    "    path = os.path.join(outputs_path, f'plots/cm-{trial_id}.png')\n",
    "    plt.savefig(path)\n",
    "    plt.close()  \n",
    "            \n",
    "            # save the model\n",
    "    # torch.save(model.state_dict(), f'./models/RESNET/RESNET-18_{trial_id}.pth')     \n",
    "    elapsed_time = time.time() - st\n",
    "    \n",
    "    write_to_table(epochs, opt_name, criterion, batch_size, learning_rate, elapsed_time, train_loss, train_accuracy, valid_loss, valid_accuracy, trial_id, scheduler.__class__.__name__, device, aug, weight_freezing, f1, precision, recall)\n",
    "    \n",
    "    create_plot(epochs, train_accuracy, valid_accuracy, train_loss, valid_loss)\n",
    "    \n",
    "    # output_details_to_text(epochs, optimizer, scheduler.__class__.__name__, criterion, batch_size, learning_rate, iteratior_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids\n",
    "criterions = [nn.CrossEntropyLoss()]\n",
    "optimizers = [optim.Adam, optim.SGD]\n",
    "# activations = [F.relu] #not used\n",
    "learning_rates = [0.0001,0.001, 0.005, 0.01 ]\n",
    "epochs = [30, 10, 50]\n",
    "batch_size = [32, 64]\n",
    "schedulers = [optim.lr_scheduler.ExponentialLR]\n",
    "devices = [torch.device(\"mps\")]\n",
    "aug = [True, False]\n",
    "weight_freezing = [True, False]\n",
    "\n",
    "# Create all possible parameter combinations\n",
    "parameter_grid = itertools.product(learning_rates, batch_size, epochs, schedulers, optimizers, criterions, devices, weight_freezing, aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asserelfeki/dev/ml/env/lib/python3.8/site-packages/torchmetrics/utilities/checks.py:49: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343685278/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  if ignore_index is None and target.min() < 0:\n"
     ]
    }
   ],
   "source": [
    "for i, params in enumerate(parameter_grid):\n",
    "    learning_rate, batch_size, epochs, scheduler, optimizer, criterion, device, aug, weight_freezing = params \n",
    "    \n",
    "    data_transforms = create_aug(aug)\n",
    "    \n",
    "    train_dataset = FERPlusDataset(os.path.join(train_folder_path,\"label.csv\"), train_folder_path, transform=data_transforms['train'])\n",
    "    valid_dataset = FERPlusDataset(os.path.join(valid_folder_path, \"label.csv\"), valid_folder_path, transform=data_transforms['valid'])\n",
    "    # test_dataset = FERPlusDataset(os.path.join(test_folder_path, \"label.csv\"), test_folder_path, transform=data_transforms['val'])\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    if weight_freezing:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    num_classes = train_dataset.classes\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    model.to(device)\n",
    "    train_and_validate(epochs, optimizer, scheduler , criterion, model, trainloader, validloader, batch_size, learning_rate, i+1, device, aug, weight_freezing)\n",
    "    torch.save(model.state_dict(), f'{outputs_path}/models/trial_{i+1}.pth')\n",
    "    \n",
    "    plt.savefig(f\"{outputs_path}/plots/trial{i}.png\")\n",
    "    plt.close()\n",
    "    plt.close('all')\n",
    "    # make sure there is no memory leaks .. not working as expected \n",
    "    torch.mps.empty_cache()\n",
    "    # clear ram\n",
    "    del model\n",
    "    # free memory\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    # free dataloader memory \n",
    "    del trainloader\n",
    "    del validloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just for Debugging\n",
    "data_transforms = create_aug(True)\n",
    "train_dataset = FERPlusDataset(os.path.join(train_folder_path,\"label.csv\"), train_folder_path, transform=data_transforms['train'])\n",
    "valid_dataset = FERPlusDataset(os.path.join(valid_folder_path, \"label.csv\"), valid_folder_path, transform=data_transforms['valid'])\n",
    "test_dataset = FERPlusDataset(os.path.join(test_folder_path, \"label.csv\"), test_folder_path, transform=data_transforms['valid'])\n",
    "# Define the emotion labels\n",
    "emotion_labels = ['neutral', 'happiness', 'surprise', 'sadness', 'anger', 'disgust', 'fear', 'contempt', 'unknown', 'NF']\n",
    "\n",
    "# Randomly select and display images from the train set\n",
    "train_indices = np.random.choice(len(train_dataset), size=5, replace=False)\n",
    "train_images = [train_dataset[i]['image'] for i in train_indices]\n",
    "train_labels = [train_dataset[i]['emotions'] for i in train_indices]\n",
    "\n",
    "# Randomly select and display images from the validation set\n",
    "valid_indices = np.random.choice(len(valid_dataset), size=5, replace=False)\n",
    "valid_images = [valid_dataset[i]['image'] for i in valid_indices]\n",
    "valid_labels = [valid_dataset[i]['emotions'] for i in valid_indices]\n",
    "\n",
    "# Randomly select and display images from the test set\n",
    "test_indices = np.random.choice(len(test_dataset), size=5, replace=False)\n",
    "test_images = [test_dataset[i]['image'] for i in test_indices]\n",
    "test_labels = [test_dataset[i]['emotions'] for i in test_indices]\n",
    "\n",
    "# Display the images and labels\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "for i, (image, label) in enumerate(zip(train_images, train_labels)):\n",
    "    axes[0, i].imshow(image.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[0, i].set_title('Train Image')\n",
    "    axes[0, i].text(0, 5, emotion_labels[np.argmax(label)], color='red')\n",
    "\n",
    "for i, (image, label) in enumerate(zip(valid_images, valid_labels)):\n",
    "    axes[1, i].imshow(image.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    axes[1, i].set_title('Valid Image')\n",
    "    axes[1, i].text(0, 5, emotion_labels[np.argmax(label)], color='red')\n",
    "\n",
    "for i, (image, label) in enumerate(zip(test_images, test_labels)):\n",
    "    axes[2, i].imshow(image.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    axes[2, i].set_title('Test Image')\n",
    "    axes[2, i].text(0, 5, emotion_labels[np.argmax(label)], color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for classess names in FERplus dataset\n",
    "classes = {\n",
    "    0: 'Neutral',\n",
    "    1: 'Happinnes',\n",
    "    2: 'Surprise',\n",
    "    3: 'Sadness',\n",
    "    4: 'Anger',\n",
    "    5: 'Disgust',\n",
    "    6: 'Fear',\n",
    "    7: 'Contempt',\n",
    "    8: 'Unknown',\n",
    "    9: 'NF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1000\n",
    "\n",
    "np_img = test_dataset[idx]['image']\n",
    "plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "plt.show()\n",
    "plt.close()\n",
    "print (f\"the original label was {classes[test_dataset[idx]['emotions'].argmax(0).item()]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchmetrics_accuracy = Accuracy(task='multiclass', num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FERPlusDataset(os.path.join(test_folder_path, \"label.csv\"), test_folder_path, transform=data_transforms['valid'])\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "\n",
    "\n",
    "# test model on the test data set\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "def test_model(model, test_loader, dataset):\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_accuracy = []\n",
    "    wrong = 0\n",
    "    with torch.inference_mode():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            labels = data['emotions']\n",
    "            inputs = data['image']\n",
    "            output = model(inputs)\n",
    "            # print(\"out: \", output.shape)\n",
    "            # print(\"labels: \", labels.shape)\n",
    "            # print(labels.shape)\n",
    "            # print(f\"test loader length:  {len(test_loader)}\")\n",
    "            # show the first 10 images and their truth labels and their predictions\n",
    "            if i < len(test_loader):\n",
    "                for j in range(len(inputs)):\n",
    "                    # if classes[labels[j].argmax(0).item()] != classes[output[j].argmax(0).item()] :\n",
    "                    #     wrong +=1\n",
    "                    \n",
    "                    \n",
    "                    file_name = \"mymodel.txt\"\n",
    "                    output_file = open(file_name, \"a\")\n",
    "                    prediction = classes[labels[j].argmax(0).item()] == classes[output[j].argmax(0).item()]\n",
    "                    \n",
    "                    output_file.write(f\"image: {i * batch_size + j} was {prediction}\\n\")\n",
    "                    output_file.write(f\"predicted label was: {classes[output[j].argmax(0).item()]} and the original label was {classes[labels[j].argmax(0).item()]}\\n\")\n",
    "                    output_file.write(\"=\"*50)\n",
    "                    output_file.write(\"\\n\")\n",
    "                    # if j == 10:\n",
    "                    #     print(\"one example:\")\n",
    "                    #     np_img = test_dataset[i * batch_size + j]['image']\n",
    "                    #     plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "                    #     plt.show()\n",
    "                    #     plt.close()\n",
    "                    #     print('-'*50)\n",
    "                        \n",
    "                    # print(labels[i].argmax().item())\n",
    "                    # if classes[labels[j].argmax(0).item()] == classes[output[j].argmax(0).item()]:\n",
    "                    #     print(\"hoppppaaaaaaaaaa\")\n",
    "                    #     print('image:', i * batch_size + j)\n",
    "                        \n",
    "                    #     print('truth:', classes[labels[j].argmax(0).item()])\n",
    "                    #     print('prediction:', classes[output[j].argmax(0).item()])\n",
    "                    #     print('='*50)\n",
    "                    # plt.close('all')    \n",
    "            output_file.close()\n",
    "            # measure accuracy\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            # torchmetrics_accuracy(predicted, labels)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_accuracy.append(torchmetrics_accuracy(predicted, labels))\n",
    "        # print total accuracy\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n",
    "        print(f\"correct: {correct}, total: {total}\")\n",
    "        print(test_accuracy)\n",
    "test_model(model, testloader, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/RESNET/RESNET-18_11.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        labels = data['emotions'].to(device)\n",
    "        images = data['image'].to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        \n",
    "        test_loss += criterion(outputs, labels).item() \n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "test_loss /= total_samples\n",
    "test_accuracy = test_correct / total_samples\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f} | Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- change first layer \n",
    "2- documteation bta3 tranfer learning and resnet \n",
    "3- loss fix \n",
    "4- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
